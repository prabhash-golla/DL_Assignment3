{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11300811,"sourceType":"datasetVersion","datasetId":7067139},{"sourceId":11390883,"sourceType":"datasetVersion","datasetId":7133521}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import json, os, random\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:36.965177Z","iopub.execute_input":"2025-04-13T23:57:36.965454Z","iopub.status.idle":"2025-04-13T23:57:36.969489Z","shell.execute_reply.started":"2025-04-13T23:57:36.965434Z","shell.execute_reply":"2025-04-13T23:57:36.968695Z"}},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"### Import Captions from Part-B","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/captions-from-part-b/masked_image_captions_custom_model.json\", \"r\") as f:\n    mymodel_captions = json.load(f)\n\nwith open(\"/kaggle/input/captions-from-part-b/smolvlm_masked_image_captions.json\", \"r\") as f:\n    smolvlm_captions_original = json.load(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:36.970539Z","iopub.execute_input":"2025-04-13T23:57:36.970744Z","iopub.status.idle":"2025-04-13T23:57:37.008872Z","shell.execute_reply.started":"2025-04-13T23:57:36.970729Z","shell.execute_reply":"2025-04-13T23:57:37.008370Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"\nsmolvlm_captions = {}\n\ndef clean_caption(caption):\n    if \"Assistant:\" in caption:\n        return caption.split(\"Assistant:\")[1].strip()\n    return caption\n\n\nfor pct in smolvlm_captions_original:\n    smolvlm_captions[pct] = {}\n    for img_name, caption in smolvlm_captions_original[pct].items():\n        smolvlm_captions[pct][img_name] = clean_caption(caption)\n\n\nprint(mymodel_captions[\"10\"][\"test_1.jpg\"])\nprint(\"\\nBefore cleaning (smolvlm):\")\nprint(smolvlm_captions_original[\"10\"][\"test_1.jpg\"])\nprint(\"\\nAfter cleaning (smolvlm):\")\nprint(smolvlm_captions[\"10\"][\"test_1.jpg\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.009804Z","iopub.execute_input":"2025-04-13T23:57:37.010044Z","iopub.status.idle":"2025-04-13T23:57:37.016915Z","shell.execute_reply.started":"2025-04-13T23:57:37.010030Z","shell.execute_reply":"2025-04-13T23:57:37.016365Z"}},"outputs":[{"name":"stdout","text":"A man is standing on a sidewalk. He is wearing a black jacket and a black helmet. He is holding a white and red cell phone. There is a man standing on the sidewalk next to him. The man is wearing a black shirt and a\n\nBefore cleaning (smolvlm):\nUser:<image>What's in this image?\nAssistant: A busy city street with a modern building in the background.\n\nAfter cleaning (smolvlm):\nA busy city street with a modern building in the background.\n","output_type":"stream"}],"execution_count":86},{"cell_type":"markdown","source":"### Load the captions given in the dataset ( Provided in the assignment itself )","metadata":{}},{"cell_type":"code","source":"def load_original_captions(base_path=\"/kaggle/input/dataset/custom_captions_dataset\"):\n    all_splits = [\"train\", \"val\", \"test\"]\n    original_captions = {}\n    for split in all_splits:\n        df = pd.read_csv(os.path.join(base_path, f\"{split}.csv\"))\n        for _, row in df.iterrows():\n            original_captions[row['filename']] = row['caption']\n    return original_captions\n\noriginal_captions = load_original_captions()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.017499Z","iopub.execute_input":"2025-04-13T23:57:37.017717Z","iopub.status.idle":"2025-04-13T23:57:37.322967Z","shell.execute_reply.started":"2025-04-13T23:57:37.017703Z","shell.execute_reply":"2025-04-13T23:57:37.322423Z"}},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"### Create dataset with balanced classes","metadata":{}},{"cell_type":"markdown","source":"#### label : 1 for custom model \n#### label : 0 for smolvlm model","metadata":{}},{"cell_type":"code","source":"def create_classifier_dataset(smol_data, custom_data, original_caps):\n    dataset = []\n    for pct in smol_data:\n        pct_str = str(pct)\n        for img_name in smol_data[pct_str]:\n            if img_name in custom_data[pct_str] and img_name in original_caps:\n                orig = original_caps[img_name]\n                dataset.append({\n                    \"original\": orig,\n                    \"generated\": smol_data[pct_str][img_name],\n                    \"occlusion\": pct_str,\n                    \"label\": 0,  # SmolVLM (Model A)\n                    \"img_name\": img_name\n                })\n                dataset.append({\n                    \"original\": orig,\n                    \"generated\": custom_data[pct_str][img_name],\n                    \"occlusion\": pct_str,\n                    \"label\": 1,  # Custom model (Model B)\n                    \"img_name\": img_name\n                })\n    return dataset\n\nfull_data = create_classifier_dataset(smolvlm_captions, mymodel_captions, original_captions)\nprint(f\"dataset length - {len(full_data)} examples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.324720Z","iopub.execute_input":"2025-04-13T23:57:37.324920Z","iopub.status.idle":"2025-04-13T23:57:37.334853Z","shell.execute_reply.started":"2025-04-13T23:57:37.324905Z","shell.execute_reply":"2025-04-13T23:57:37.334315Z"}},"outputs":[{"name":"stdout","text":"dataset length - 5568 examples\n","output_type":"stream"}],"execution_count":88},{"cell_type":"markdown","source":"### Split the data in 70:10:20 ratio ( train , val , test ) ","metadata":{}},{"cell_type":"code","source":"def split_by_image(data, train_ratio=0.7, val_ratio=0.1):\n    \n    random.seed(42)\n    images = {}\n    \n    for d in data:\n        img_id = d[\"img_name\"]\n        if img_id not in images:\n            images[img_id] = []\n        images[img_id].append(d)\n    \n    image_ids = list(images.keys())\n    random.shuffle(image_ids)\n    \n    n = len(image_ids)\n    train_ids = set(image_ids[:int(train_ratio * n)])\n    val_ids = set(image_ids[int(train_ratio * n):int((train_ratio + val_ratio) * n)])\n    test_ids = set(image_ids[int((train_ratio + val_ratio) * n):])\n    \n    train_set, val_set, test_set = [], [], []\n    \n    for img_id in train_ids:\n        train_set.extend(images[img_id])\n    \n    for img_id in val_ids:\n        val_set.extend(images[img_id])\n    \n    for img_id in test_ids:\n        test_set.extend(images[img_id])\n    \n    return train_set, val_set, test_set\n\ntrain_data, val_data, test_data = split_by_image(full_data)\nprint(f\"Length of train_data : {len(train_data)}\")\nprint(f\"Length of val_data   : {len(val_data)}\")\nprint(f\"Length of test_data  : {len(test_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.335577Z","iopub.execute_input":"2025-04-13T23:57:37.335834Z","iopub.status.idle":"2025-04-13T23:57:37.343406Z","shell.execute_reply.started":"2025-04-13T23:57:37.335813Z","shell.execute_reply":"2025-04-13T23:57:37.342772Z"}},"outputs":[{"name":"stdout","text":"Length of train_data : 3894\nLength of val_data   : 558\nLength of test_data  : 1116\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"class CaptionComparisonDataset(Dataset):\n    def __init__(self, data, tokenizer, max_len=128):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        \n        # <original_caption> <SEP> <generated_caption> <SEP> <perturbation_percentage>\n        text = f\"{item['original']} [SEP] {item['generated']} [SEP] {item['occlusion']}\"\n        \n        # Use proper tokenization with attention mask\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(item['label'], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.344075Z","iopub.execute_input":"2025-04-13T23:57:37.344350Z","iopub.status.idle":"2025-04-13T23:57:37.348941Z","shell.execute_reply.started":"2025-04-13T23:57:37.344336Z","shell.execute_reply":"2025-04-13T23:57:37.348290Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"### Model Definition (BERT-base with custom linear layers)\n#### In CaptionClassifier class :\n##### Freezed the BERT embeddings to prevent overfitting and freezed the first 8 layers to reduce trainable parameters\n\n#### Pooled Output : \n##### The special [CLS] token's final representation after being passed through a linear layer and tanh activation. \n##### It's a single vector that captures the aggregate meaning of the entire input sequence, designed specifically for classification tasks","metadata":{}},{"cell_type":"code","source":"class CaptionClassifier(nn.Module):\n    def __init__(self, dropout_rate=0.3):\n        super(CaptionClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        \n        for param in self.bert.embeddings.parameters():\n            param.requires_grad = False\n        \n        for layer in self.bert.encoder.layer[:8]:\n            for param in layer.parameters():\n                param.requires_grad = False\n        \n        hidden_size = self.bert.config.hidden_size\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(128, 2)  \n        )\n        self._init_weights()\n    \n    def _init_weights(self):\n        for module in self.classifier:\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_normal_(module.weight)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        pooled_output = outputs.pooler_output        \n        return self.classifier(pooled_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.349453Z","iopub.execute_input":"2025-04-13T23:57:37.349683Z","iopub.status.idle":"2025-04-13T23:57:37.355574Z","shell.execute_reply.started":"2025-04-13T23:57:37.349659Z","shell.execute_reply":"2025-04-13T23:57:37.354913Z"}},"outputs":[],"execution_count":91},{"cell_type":"markdown","source":"## Decalring tokenizer and dataset with the earlier definition of CaptionComparisonDataset","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ntrain_dataset = CaptionComparisonDataset(train_data, tokenizer)\nval_dataset = CaptionComparisonDataset(val_data, tokenizer)\ntest_dataset = CaptionComparisonDataset(test_data, tokenizer)\n\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.356291Z","iopub.execute_input":"2025-04-13T23:57:37.356465Z","iopub.status.idle":"2025-04-13T23:57:37.515024Z","shell.execute_reply.started":"2025-04-13T23:57:37.356452Z","shell.execute_reply":"2025-04-13T23:57:37.514308Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"### Training Function ( TQDM for progress tracking )","metadata":{}},{"cell_type":"code","source":"def train_classifier(model, train_loader, val_loader, optimizer, scheduler, criterion, device, epochs=3):\n    model.to(device)\n    best_val_loss = float('inf')\n    \n    train_losses = []\n    val_losses = []\n    train_accs = []\n    val_accs = []\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        correct = 0\n        total = 0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            \n            optimizer.zero_grad()            \n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            # Gradient clipping to prevent exploding gradients\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            scheduler.step()\n            train_loss += loss.item()\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            \n            progress_bar.set_postfix({\n                'loss': f\"{loss.item():.4f}\",\n                'acc': f\"{correct/total:.4f}\"\n            })\n        \n        avg_train_loss = train_loss / len(train_loader)\n        train_acc = correct / total\n        \n        train_losses.append(avg_train_loss)\n        train_accs.append(train_acc)\n        \n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['label'].to(device)\n                \n                outputs = model(input_ids, attention_mask)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                preds = outputs.argmax(dim=1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n        \n        avg_val_loss = val_loss / len(val_loader)\n        val_acc = correct / total\n        \n        val_losses.append(avg_val_loss)\n        val_accs.append(val_acc)\n        \n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n        \n       \n    return {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'train_accs': train_accs,\n        'val_accs': val_accs\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.515688Z","iopub.execute_input":"2025-04-13T23:57:37.515872Z","iopub.status.idle":"2025-04-13T23:57:37.525093Z","shell.execute_reply.started":"2025-04-13T23:57:37.515858Z","shell.execute_reply":"2025-04-13T23:57:37.524420Z"}},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":"### Evaluation Function (for macro precision, recall, and F1 scores)","metadata":{}},{"cell_type":"code","source":"def evaluate_classifier(model, dataloader, device):\n    model.eval()\n    model.to(device)\n    \n    y_true = []\n    y_pred = []\n    total_loss = 0\n    criterion = nn.CrossEntropyLoss()\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            \n            preds = torch.argmax(outputs, dim=1)\n\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = sum(1 for t, p in zip(y_true, y_pred) if t == p) / len(y_true)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n    \n    return {\n        \"Loss\": avg_loss,\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1\": f1\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.526787Z","iopub.execute_input":"2025-04-13T23:57:37.527261Z","iopub.status.idle":"2025-04-13T23:57:37.532666Z","shell.execute_reply.started":"2025-04-13T23:57:37.527245Z","shell.execute_reply":"2025-04-13T23:57:37.531970Z"}},"outputs":[],"execution_count":94},{"cell_type":"markdown","source":"### Analysis by Occlusion Level","metadata":{}},{"cell_type":"code","source":"def analyze_by_occlusion(model, test_data, tokenizer, device):\n    model.eval()\n    results_by_occlusion = {\"10\": {\"correct\": 0, \"total\": 0},\n                           \"50\": {\"correct\": 0, \"total\": 0},\n                           \"80\": {\"correct\": 0, \"total\": 0}}\n    \n    dataset = CaptionComparisonDataset(test_data, tokenizer)\n    loader = DataLoader(dataset, batch_size=16)\n    \n    with torch.no_grad():\n        for i, batch in enumerate(loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids, attention_mask)\n            preds = torch.argmax(outputs, dim=1)\n            \n            # Match predictions with original data to get occlusion level\n            for j in range(len(preds)):\n                idx = i * 16 + j\n                if idx < len(test_data):\n                    occlusion = test_data[idx][\"occlusion\"]\n                    correct = preds[j].item() == labels[j].item()\n                    \n                    results_by_occlusion[occlusion][\"total\"] += 1\n                    if correct:\n                        results_by_occlusion[occlusion][\"correct\"] += 1\n    \n    occlusion_results = {}\n    for occlusion in results_by_occlusion:\n        correct = results_by_occlusion[occlusion][\"correct\"]\n        total = results_by_occlusion[occlusion][\"total\"]\n        accuracy = correct / total if total > 0 else 0\n        occlusion_results[occlusion] = accuracy\n        print(f\"Occlusion {occlusion}%: Accuracy = {accuracy:.4f} ({correct}/{total})\")\n    \n    return occlusion_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.533253Z","iopub.execute_input":"2025-04-13T23:57:37.533422Z","iopub.status.idle":"2025-04-13T23:57:37.539530Z","shell.execute_reply.started":"2025-04-13T23:57:37.533409Z","shell.execute_reply":"2025-04-13T23:57:37.538983Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"### Defining the parameters and Evaluate","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = CaptionClassifier(dropout_rate=0.3)\noptimizer = torch.optim.AdamW(\n    [p for p in model.parameters() if p.requires_grad],\n    lr=2e-5,\n    weight_decay=0.01\n)\n\ncriterion = nn.CrossEntropyLoss()\nnum_epochs = 3\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * total_steps),\n    num_training_steps=total_steps\n)\n\ntrain_classifier(\n    model, \n    train_loader, \n    val_loader, \n    optimizer, \n    scheduler, \n    criterion, \n    device, \n    epochs=num_epochs\n)\n\nprint(\"\\n\")\nmetrics = evaluate_classifier(model, test_loader, device)\n\nprint(f\"Macro Precision: {metrics['Precision']:.4f}\")\nprint(f\"Macro Recall: {metrics['Recall']:.4f}\")\nprint(f\"Macro F1: {metrics['F1']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:57:37.540155Z","iopub.execute_input":"2025-04-13T23:57:37.540348Z","iopub.status.idle":"2025-04-13T23:59:24.689383Z","shell.execute_reply.started":"2025-04-13T23:57:37.540334Z","shell.execute_reply":"2025-04-13T23:59:24.688670Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/3 [Train]: 100%|██████████| 244/244 [00:31<00:00,  7.84it/s, loss=0.0074, acc=0.8546]\nEpoch 1/3 [Val]: 100%|██████████| 35/35 [00:02<00:00, 12.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/3\n  Train Loss: 0.3307 | Train Acc: 0.8546\n  Val Loss: 0.1095 | Val Acc: 0.9588\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Train]: 100%|██████████| 244/244 [00:31<00:00,  7.87it/s, loss=0.2664, acc=0.9620]\nEpoch 2/3 [Val]: 100%|██████████| 35/35 [00:02<00:00, 12.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/3\n  Train Loss: 0.1149 | Train Acc: 0.9620\n  Val Loss: 0.0597 | Val Acc: 0.9767\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3 [Train]: 100%|██████████| 244/244 [00:31<00:00,  7.86it/s, loss=0.0286, acc=0.9725]\nEpoch 3/3 [Val]: 100%|██████████| 35/35 [00:02<00:00, 12.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/3\n  Train Loss: 0.0856 | Train Acc: 0.9725\n  Val Loss: 0.0496 | Val Acc: 0.9803\n\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 70/70 [00:05<00:00, 13.00it/s]","output_type":"stream"},{"name":"stdout","text":"Macro Precision: 0.9840\nMacro Recall: 0.9839\nMacro F1: 0.9839\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":96}]}